\chapter{Experiment Description}

There are two qualities which we want to analyze with respect to~the~game
and the implemented AI algorithms:

\begin{itemize}
    \item Identify potential asymmetries in game balance
    \item Compare methodologies used by the AI algorithms
\end{itemize}

To this end, we conducted five experiments, split according to their purpose.
The following sections elaborate on the experiments and their results.

\section{Game Balance Experiments}

As mentioned in \autoref{chap:gamedesign}, the game features a degree of asymmetry.
The order in which players take their turns inherently changes the viability of certain
strategies, because players in different positions have different information sections
available to them. For example, the~player in~the~first position has perfect information
about which colonist was removed from play during the colonist pick phase, while
the~second and third players do not have such certainty.

Most importantly however, a~player's colonist is revealed at the~start of their
turn. This means that if the player in the fourth position is a~Spy or an~Opportunist,
they will know all the other players' colonists when their turn comes around.
This means that this player will be able to target any player with their targeted
ability without the fear of missing or hitting an unintended target.

With these things in mind, we can hypothesize that players in the earlier positions
have an easier time achieving synergy-based strategies, since they get priority
when picking colonists. On the other hand, we can also hypothesize that players in~later
positions will benefit from play based around using targeted colonist abilities.

In Chess, it is widely agreed that the white player has an~advantage \cite{Streeter46}. 
Similarly, we aim to~discover whether player ordering confers
a~measurable advantage to any player in \emph{Colonizers}.
We will conduct this experiment with the null hypothesis --- we assume
that there is no significant advantage for any player ordering.
\pagebreak

\subsection{Description}

We conducted two experiments in this section. In both of them, four identical AIs
played 1000 games against each other. In the first experiment, the AI in question was
\texttt{RandomIntelligence}, and in the second
experiment it was \texttt{HeuristicIntelligence}.

All random events were seeded, and the results of the games were captured in JSON
(JavaScript Object Notation) files.
The results were then parsed and analyzed. The JSON result files can be found
in~the~attached source code, refer to \autoref{chap:experimentdocs} for more information
on their location and semantics.

The random seeds used by application components during the experiment were as follows:
\begin{itemize}
    \item \texttt{RandomIntelligence}: seed 42
    \item \texttt{HeuristicIntelligence}: seed 97
    \item \texttt{GameConstants}: seed was changed every game to prevent the same game from
        being played 1000 times. The seeds were generated by~a~C\# 
        random number generator seeded with 42.
\end{itemize}

\subsection{Findings}

TODO

\section{Algorithm Comparison Experiments}

We have implemented four algorithms in this thesis --- \texttt{RandomIntelligence},
\texttt{HeuristicIntelligence}, \texttt{MaxnIntelligence} and \texttt{ISMCTSIntelligence}.
In order to determine the qualities of said algorithms, we will analyze their differences,
along with their advantages and disadvantages. We will also look at how the algorithms
perform in play against each other, with the hopes of determining which algorithm
is the most suitable for a game like \emph{Colonizers}.

\subsection{Description}

TODO

\subsection{Findings}

WORK IN PROGRESS
